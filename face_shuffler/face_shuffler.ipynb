{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_shuffler",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdj0ZyqheVzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67370726-2f1a-4846-defc-252d6fd6ff74"
      },
      "source": [
        "# url for image\r\n",
        "img_url = 'https://postfiles.pstatic.net/MjAxOTA3MDdfMjU4/MDAxNTYyNTAxODM2NTIw.VRpcxIr6Mcn_yyiNgmy17gwThBm6mTDbM7WdwzsmK5Eg.94fshQcch7MHY0TCUpMnwAXS0dsIMT6EmslaGAA1E58g.JPEG.pola0216/%EC%84%9C%EA%B0%95%EC%A4%80%EB%82%A8%EC%B9%9C%EC%A7%A416.jpg?type=w966'\r\n",
        "\r\n",
        "# model dir (Directory)\r\n",
        "model_dir = 'shape_predictor_68_face_landmarks.dat'\r\n",
        "\r\n",
        "!pip install python-pptx\r\n",
        "\r\n",
        "# import the necessary packages\r\n",
        "from collections import OrderedDict\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "import dlib\r\n",
        "import imutils\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "\r\n",
        "# packages for image retrieval\r\n",
        "from urllib import request\r\n",
        "from PIL import Image\r\n",
        "from io import BytesIO"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-pptx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/86/eb979f7b0333ec769041aae36df8b9f1bd8bea5bbad44620663890dce561/python-pptx-0.6.18.tar.gz (8.9MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from python-pptx) (4.2.6)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from python-pptx) (7.0.0)\n",
            "Collecting XlsxWriter>=0.5.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/41/bf1aae04932d1eaffee1fc5f8b38ca47bbbf07d765129539bc4bcce1ce0c/XlsxWriter-1.3.7-py2.py3-none-any.whl (144kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 45.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: python-pptx\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.18-cp36-none-any.whl size=275707 sha256=f5d38118292da2f8109d9043b80b6720c6290dbff515d5060fbd61ad98f885d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/1f/2c/29acca422b420a0b5210bd2cd7e9669804520d602d2462f20b\n",
            "Successfully built python-pptx\n",
            "Installing collected packages: XlsxWriter, python-pptx\n",
            "Successfully installed XlsxWriter-1.3.7 python-pptx-0.6.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OICHUjUneXiI",
        "outputId": "dab2655b-eda7-453f-a12a-9c77472e2ebc"
      },
      "source": [
        "facial_features_cordinates = {}\r\n",
        "\r\n",
        "# define a dictionary that maps the indexes of the facial\r\n",
        "# landmarks to specific face regions\r\n",
        "FACIAL_LANDMARKS_INDEXES = OrderedDict([\r\n",
        "    (\"Mouth\", (48, 68)),\r\n",
        "    (\"Right_Eyebrow\", (17, 22)),\r\n",
        "    (\"Left_Eyebrow\", (22, 27)),\r\n",
        "    (\"Right_Eye\", (36, 42)),\r\n",
        "    (\"Left_Eye\", (42, 48)),\r\n",
        "    (\"Nose\", (27, 35)),\r\n",
        "    (\"Jaw\", (0, 17))\r\n",
        "])\r\n",
        "                                                                                                                                                                                                    \r\n",
        "\r\n",
        "def shape_to_numpy_array(shape, dtype=\"int\"):\r\n",
        "    # initialize the list of (x, y)-coordinates\r\n",
        "    coordinates = np.zeros((68, 2), dtype=dtype)\r\n",
        "\r\n",
        "    # loop over the 68 facial landmarks and convert them\r\n",
        "    # to a 2-tuple of (x, y)-coordinates\r\n",
        "    for i in range(0, 68):\r\n",
        "        coordinates[i] = (shape.part(i).x, shape.part(i).y)\r\n",
        "\r\n",
        "    # return the list of (x, y)-coordinates\r\n",
        "    return coordinates\r\n",
        "\r\n",
        "\r\n",
        "def visualize_facial_landmarks(image, shape, colors=None, alpha=0.75):\r\n",
        "    # create two copies of the input image -- one for the\r\n",
        "    # overlay and one for the final output image\r\n",
        "    overlay = image.copy()\r\n",
        "    output = image.copy()\r\n",
        "\r\n",
        "    # if the colors list is None, initialize it with a unique\r\n",
        "    # color for each facial landmark region\r\n",
        "    if colors is None:\r\n",
        "        colors = [(19, 199, 109), (79, 76, 240), (230, 159, 23),\r\n",
        "                  (168, 100, 168), (158, 163, 32),\r\n",
        "                  (163, 38, 32), (180, 42, 220)]\r\n",
        "\r\n",
        "    # loop over the facial landmark regions individually\r\n",
        "    for (i, name) in enumerate(FACIAL_LANDMARKS_INDEXES.keys()):\r\n",
        "        # grab the (x, y)-coordinates associated with the\r\n",
        "        # face landmark\r\n",
        "        (j, k) = FACIAL_LANDMARKS_INDEXES[name]\r\n",
        "        pts = shape[j:k]\r\n",
        "        facial_features_cordinates[name] = pts\r\n",
        "\r\n",
        "        # check if are supposed to draw the jawline\r\n",
        "        if name == \"Jaw\":\r\n",
        "            # since the jawline is a non-enclosed facial region,\r\n",
        "            # just draw lines between the (x, y)-coordinates\r\n",
        "            for l in range(1, len(pts)):\r\n",
        "                ptA = tuple(pts[l - 1])\r\n",
        "                ptB = tuple(pts[l])\r\n",
        "                cv2.line(overlay, ptA, ptB, colors[i], 2)\r\n",
        "\r\n",
        "        # otherwise, compute the convex hull of the facial\r\n",
        "        # landmark coordinates points and display it\r\n",
        "        else:\r\n",
        "            hull = cv2.convexHull(pts)\r\n",
        "            cv2.drawContours(overlay, [hull], -1, colors[i], -1)\r\n",
        "\r\n",
        "    # apply the transparent overlay\r\n",
        "    cv2.addWeighted(overlay, alpha, output, 1 - alpha, 0, output)\r\n",
        "\r\n",
        "    # return the output image\r\n",
        "    # print(facial_features_cordinates)\r\n",
        "    return output\r\n",
        "\r\n",
        "\r\n",
        "# initialize dlib's face detector (HOG-based) and then create\r\n",
        "# the facial landmark predictor\r\n",
        "detector = dlib.get_frontal_face_detector()\r\n",
        "predictor = dlib.shape_predictor(model_dir)\r\n",
        "\r\n",
        "# load the input image, resize it, and convert it to grayscale\r\n",
        "# image = cv2.imread('/images/image_1.jpg')\r\n",
        "res = request.urlopen(img_url).read()\r\n",
        "pil_image = Image.open(BytesIO(res)).convert('RGB')\r\n",
        "image = np.array(pil_image)[:, :, ::-1].copy()\r\n",
        "\r\n",
        "image = imutils.resize(image, width=2000)\r\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n",
        "\r\n",
        "# detect faces in the grayscale image\r\n",
        "rects = detector(gray, 1)\r\n",
        "\r\n",
        "# loop over the face detections\r\n",
        "for (i, rect) in enumerate(rects):\r\n",
        "    # determine the facial landmarks for the face region, then\r\n",
        "    # convert the landmark (x, y)-coordinates to a NumPy array\r\n",
        "    shape = predictor(gray, rect)\r\n",
        "    shape = shape_to_numpy_array(shape)\r\n",
        "\r\n",
        "    output = visualize_facial_landmarks(image, shape)\r\n",
        "\r\n",
        "    # cv2.imshow(\"Image\", output)\r\n",
        "    # cv2_imshow(output)\r\n",
        "    # cv2.waitKey(0)\r\n",
        "\r\n",
        "\r\n",
        "# =========================================================\r\n",
        "\r\n",
        "\r\n",
        "def face_shuffle(img, part_list=['Left_Eye', 'Nose', 'Right_Eye', 'Mouth']):\r\n",
        "  crop_img_list = []\r\n",
        "\r\n",
        "  for part in part_list:\r\n",
        "    tmp_x = facial_features_cordinates[part][:, 0]\r\n",
        "    tmp_x_min, tmp_x_max = tmp_x.min(), tmp_x.max()\r\n",
        "\r\n",
        "    tmp_y = facial_features_cordinates[part][:, 1]\r\n",
        "    tmp_y_min, tmp_y_max = tmp_y.min(), tmp_y.max()\r\n",
        "\r\n",
        "    if part.endswith('Eye'):\r\n",
        "      tmp_y_min = int(tmp_y_min*0.90)\r\n",
        "    if part.endswith('Nose'):\r\n",
        "      tmp_x_min = int(tmp_x_min*0.95)\r\n",
        "      tmp_x_max = int(tmp_x_max*1.1)\r\n",
        "\r\n",
        "    crop_img = image[tmp_y_min:tmp_y_max, tmp_x_min:tmp_x_max]\r\n",
        "    crop_img_list.append(crop_img)\r\n",
        "  return crop_img_list\r\n",
        "\r\n",
        "\r\n",
        "# get 4 parts of detected face (Leye, Nose, Reye, Mouth)\r\n",
        "# print(facial_features_cordinates.keys())\r\n",
        "part_name_list = ['Left_Eye', 'Nose', 'Right_Eye', 'Mouth']\r\n",
        "part_img_list = face_shuffle(image, part_list=part_name_list)\r\n",
        "# for img in part_img_list:\r\n",
        "#   cv2_imshow(img)\r\n",
        "#   print()\r\n",
        "#   cv2.waitKey(0)\r\n",
        "\r\n",
        "\r\n",
        "# =========================================================\r\n",
        "\r\n",
        "\r\n",
        "# save img files\r\n",
        "part_filename_list = [i+'.png' for i in part_name_list]\r\n",
        "original_filename = 'original.png'\r\n",
        "\r\n",
        "for name, arr in zip(part_filename_list, part_img_list):\r\n",
        "  im = Image.fromarray(cv2.cvtColor(arr, cv2.COLOR_BGR2RGB))\r\n",
        "  im.save(name, dpi=(5000, 5000))\r\n",
        "pil_image.save(original_filename, dpi=(5000, 5000))\r\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t      Mouth.png  original.png\tsample_data\n",
            "Left_Eye.png  Nose.png\t Right_Eye.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "075x7sZYpW2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65dbefb-2de5-4887-a990-b19517dce2a1"
      },
      "source": [
        "# Generate final pptx file\r\n",
        "from pptx import Presentation\r\n",
        "from pptx.util import Inches\r\n",
        "\r\n",
        "def make_ppt(out_ppt_name, part_filename_list, original_filename):\r\n",
        "    # Presentation()을 일종의 템플릿 객체\r\n",
        "    this_prs = Presentation()\r\n",
        "    \"\"\"\r\n",
        "    slide_layout[0]는 title, subtitle로 구성된 제목 슬라이드 \r\n",
        "    slide_layout[1]는 title, text로 구성된 일반적인 슬라이드 레이아웃\r\n",
        "    slide_layout[6]은 빈 슬라이드\r\n",
        "    \"\"\"\r\n",
        "    slide_layout = this_prs.slide_layouts[6]\r\n",
        "    \r\n",
        "    this_slide = this_prs.slides.add_slide(slide_layout)\r\n",
        "    shapes = this_slide.shapes\r\n",
        "    for idx, name in enumerate(part_filename_list):\r\n",
        "      if idx < 3:\r\n",
        "        shapes.add_picture(name, Inches(0.5+idx*3), Inches(0.5), height=Inches(2.5))\r\n",
        "      else:\r\n",
        "        shapes.add_picture(name, Inches(2.5), Inches(4), height=Inches(2.5))\r\n",
        "    \r\n",
        "    this_slide = this_prs.slides.add_slide(slide_layout)\r\n",
        "    this_slide.shapes.add_picture(original_filename, Inches(2.5), Inches(0), height=Inches(7))\r\n",
        "    \r\n",
        "    this_prs.save(out_ppt_name)\r\n",
        "    \r\n",
        "\r\n",
        "    # for title, content, img_file_name in content_lst:\r\n",
        "    #     this_slide = this_prs.slides.add_slide(slide_layout)\r\n",
        "    #     shapes = this_slide.shapes\r\n",
        "    #     shapes.title.text = title\r\n",
        "    #     shapes.placeholders[1].text = content\r\n",
        "    #     # placeholders는 개별 slide에 있는 모든 개체를 가져온다고 보면 됨. \r\n",
        "    #     #shapes.add_picture(img_stream, left, top, height=height)\r\n",
        "    #     #shapes.add_picture(img_file_name, left=Inches(5), top=Inches(10))\r\n",
        "    #     shapes.add_picture(img_file_name, Inches(2.5), Inches(3.2))\r\n",
        "    #     # 변환하지 않고 숫자로 넘기면 잘 되지 않는다. \r\n",
        "    # this_prs.save(out_ppt_name)\r\n",
        "\r\n",
        "\r\n",
        "make_ppt(out_ppt_name='face_shuffle.pptx', part_filename_list=part_filename_list, original_filename=original_filename)\r\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t   Left_Eye.png  Nose.png      Right_Eye.png\n",
            "face_shuffle.pptx  Mouth.png\t original.png  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzfXTN_LeVqa"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    }
  ]
}